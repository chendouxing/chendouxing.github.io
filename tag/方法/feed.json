{
    "version": "https://jsonfeed.org/version/1",
    "title": "蟹堡王海星 • All posts by \"方法\" tag",
    "description": "花有重开日，人无再少年",
    "home_page_url": "https://chendouxing.github.io",
    "items": [
        {
            "id": "https://chendouxing.github.io/2023/08/31/%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%B7%E4%BD%93%E6%96%B9%E6%B3%95/",
            "url": "https://chendouxing.github.io/2023/08/31/%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%B7%E4%BD%93%E6%96%B9%E6%B3%95/",
            "title": "分布式具体方法",
            "date_published": "2023-08-31T12:07:15.000Z",
            "content_html": "<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"\\assets\\css\\APlayer.min.css\"><script src=\"\\assets\\js\\APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><h1 id=\"分布式查询\"><a class=\"markdownIt-Anchor\" href=\"#分布式查询\">#</a> 分布式查询</h1>\n<h2 id=\"单查询并行处理\"><a class=\"markdownIt-Anchor\" href=\"#单查询并行处理\">#</a> 单查询并行处理</h2>\n<p><strong>数据并行</strong>：从数据并行性的角度出发，查询算子的输入数据可以看作是由若干个独立的数据块所组成，因而查询算子可以被拆分成多个子任务来并行处理输入数据中的不同数据块，从而加速整个算子的处理流程。然而，面对不同场景下的输入数据，算子的并行处理方式也会存在一些差异。</p>\n<p><strong>流水线并行</strong>：对于查询计划中的多个算子而言，它们之间通常存在着类似于生产者与消费者的依赖关系。即一个生产者算子的输出可以成为后续消费者算子的 输入。与此同时，一些消费者算子不必等待生产者算子产生所有输出，可以立即处理生产者算子已产生的数据，从而形成了一条处理 “流水线”。相较于依次完成每个算子的处理方式（即，物化方式 [19]），流水线能够避免每个算子的数据物化开 销，实现了多个算子在多个处理器核心上的并行处理，提升整体的查询效率。</p>\n<p><strong>阻塞算子</strong>：若一个算子在构建其数据结构的过程中，必须获取至少一个孩子的所有数据，则该算子称之为阻塞算子，反之则称之为非阻塞算子 [35]。</p>\n<p>在数据库查询的处理过程中，为构建一个阻塞算子的数据结构而运行的所有非阻塞算子与该阻塞算子可以组成一条查询流水线。因此，对于一个包含 N 个阻塞算子的查询计划而言，其执行过程必然包含 N 条查询流水线 [35]。如图 1.2 所示，一个两表连接查询的执行计划中包含两个阻塞算子（即，构建算子 B 和结果收集算子 RC），使得整个查询计划分成了两条查询流水线（即，P0={S→T→R→B} 和 P1={S→T→R→P→RC}）。例如，图 1.2 中 P1 流水线内的探查算子 P 依赖于 P0 流水线内的构建算子 B，因此只有流水线 P0 处理完成后，流水线 P1 才能开始处理。</p>\n<p><img src=\"/images/image-20231114133850598.png\" alt=\"image-20231114133850598\"></p>\n<ul>\n<li><strong>分布式存储中的数据</strong>：在分布式架构下，数据表会被划分成为多个数据分片存储在不同节点中。因此，一个扫描算子（Scan）可以利用分片间的数据并行性被划分成为多个扫描子任务来并行访问多个节点上的数据分片，从而加速查询的数据加载过程（例如，Oracle RAC [20] 和 Cedar [21] 中基于数据分片并行扫描机制）。此外，针对单个分片的扫描子任务还可以进一步利用分片内的数据并行性来生成更细粒度的扫描子任务，从而获得更高的扫描并行度。例如，图 1.2 中针对 R 表的扫描算子就可以生成六个扫描子任务来分别扫描两个数据分片。</li>\n</ul>\n<p><img src=\"/images/image-20231114134237225.png\" alt=\"image-20231114134237225\"></p>\n<ul>\n<li><strong>非共享内存中的数据</strong>：当面对内存中的输入数据时，查询算子会被拆分成多个子任务，从而并行地运行在不同节点的多个处理器上来处理输入数据中的不同数据块。然而，考虑到非共享内存架构（即，无共享和共享存储架构）下节点间的内存资源相互独立，<strong>每个算子子任务的输入数据块还需交由数据交换算子</strong>（例如，Shark [22] 中的 Shuffle 算子和 GPDB [23] 中的 Motion 算子，其包含传输 操作和接收操作）<strong>重分发（Redistribute）到对应的节点上</strong>，从而避免算子子任务的并行处理过程中存在跨节点的内存数据访问。例如，图 1.2 中扫描 R 表所得的数据需由多个传输操作<strong>按照特定的规则重分发</strong>给不同节点上的子任务。</li>\n<li><strong>共享内存中的数据</strong>：当输入数据位于分布式共享内存中时，查询算子也会被划分成为多个算子子任务，分布在不同节点上来处理输入数据中的不同数据块。 然而，<strong>在分布式共享内存架构下，算子的输入数据不必按照特定的划分规则（例如，范围或哈希）重分布到不同节点上。每个节点上的算子子任务可以借助于跨节点的内存访问从对应节点的内存中直接读取所需的输入数据块</strong>。例如，基于分布式共享内存架构的 Radish [34] 系统和 H2TAP [25] 系统就不需依赖任何数 据重分布操作便可将查询中的算子并行运行在不同节点上。</li>\n</ul>\n<h2 id=\"多查询并行处理\"><a class=\"markdownIt-Anchor\" href=\"#多查询并行处理\">#</a> 多查询并行处理</h2>\n<p>当同时面对多个查询请求时，查询的吞吐和响应时间都是需要关注的性能指标。因此，分布式架构中的硬件资源需要按照特定的方式 [32, 36, 37] 合理地分配给不同的查询请求，从而促成多个查询请求的并行处理，进而在一定程度上保证了查询吞吐。此外，短时间内的大规模热点查询极易打破已有分布式架构的资源上限，使其无法及时扩容来支撑大规模的并行查询请求。为此，<strong>现有的查询处理方式大都采用表 1.1 中的共享处理 [30, 38–42] 和结果重用 [43–50] 技术来压缩多查询并行处理过程中的资源开销</strong>，从而提升多查询的并行处理性能。</p>\n<p><strong>共享处理</strong>：核心思想是发掘出多个查询请求中的共享机会，并尝试利用这些机会来简化部分查询请求的处理过程，从而降低多查询并行处理过程中的资源开销，提升多查询的并行处理性能 [42]。<strong>共享处理旨在消除多查询处理过程中的重复工作，从而为多查询并行处理性能的提升节约了宝贵的硬件资源。</strong></p>\n<p><strong>结果重用</strong>：核心思想是利用过往查询处理过程中的计算结果来简化当前查询的处理过程，从而降低多查询并行处理过程中的资源开销，提升多查询的并行处理性能。常用方法为<strong>通过在查询执行计划中引入物化操作（包含物化视图），使得过往查询中频繁使用的算子或子表达式的计算结果可以被缓存起来，以便后续多个查询的处理过程可以直接重用这部分计算结果（物化视图通过将特定（子）查询的结果存储在视图表中，后续相似的查询可以直接重用视图表中已有的查询结果），从而提升多查询的并行处理性能</strong>。</p>\n",
            "tags": [
                "分布式",
                "方法"
            ]
        }
    ]
}