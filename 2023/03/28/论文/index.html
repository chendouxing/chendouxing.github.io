<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><title>论文阅读概要 | 蟹堡王海星</title><meta name="author" content="蟹堡王海星"><meta name="copyright" content="蟹堡王海星"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="# 数据一致性知识点 数据一致性分为强一致性、弱一致性和因果一致性。 强一致性要求任何数据更新在所有副本中立即可见；弱一致性不要求数据更新在所有副本中立即可见，它通过使用一定的规则使所有副本在一定时间内保持相同的状态。根据对分布式环境的分析和 CAP 定理（即在分布式系统中，一致性、可用性和分区容忍度最多只能有两个条件），强一致性导致高延迟和对网络分区的零容忍，弱一致性导致短时间内数据不一致，从而">
<meta property="og:type" content="article">
<meta property="og:title" content="论文阅读概要">
<meta property="og:url" content="https://chendouxing.github.io/2023/03/28/%E8%AE%BA%E6%96%87/index.html">
<meta property="og:site_name" content="蟹堡王海星">
<meta property="og:description" content="# 数据一致性知识点 数据一致性分为强一致性、弱一致性和因果一致性。 强一致性要求任何数据更新在所有副本中立即可见；弱一致性不要求数据更新在所有副本中立即可见，它通过使用一定的规则使所有副本在一定时间内保持相同的状态。根据对分布式环境的分析和 CAP 定理（即在分布式系统中，一致性、可用性和分区容忍度最多只能有两个条件），强一致性导致高延迟和对网络分区的零容忍，弱一致性导致短时间内数据不一致，从而">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://img1.imgtp.com/2023/08/24/0Jp2Kj9v.jpg">
<meta property="article:published_time" content="2023-03-28T10:51:10.000Z">
<meta property="article:modified_time" content="2023-08-28T12:11:48.865Z">
<meta property="article:author" content="蟹堡王海星">
<meta property="article:tag" content="论文">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img1.imgtp.com/2023/08/24/0Jp2Kj9v.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://chendouxing.github.io/2023/03/28/%E8%AE%BA%E6%96%87/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '论文阅读概要',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-08-28 20:11:48'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload="this.media='all'"><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="蟹堡王海星" type="application/atom+xml">
</head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">5</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">11</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://img1.imgtp.com/2023/08/24/0Jp2Kj9v.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="蟹堡王海星"><span class="site-name">蟹堡王海星</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">论文阅读概要</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-03-28T10:51:10.000Z" title="发表于 2023-03-28 18:51:10">2023-03-28</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-08-28T12:11:48.865Z" title="更新于 2023-08-28 20:11:48">2023-08-28</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87/">论文</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87/%E6%95%B0%E6%8D%AE%E5%BA%93%E9%A1%B6%E4%BC%9A%E8%AE%BA%E6%96%87/">数据库顶会论文</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="论文阅读概要"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h3 id="数据一致性知识点"><a class="markdownIt-Anchor" href="#数据一致性知识点">#</a> 数据一致性知识点</h3>
<p>数据一致性分为强一致性、弱一致性和因果一致性。</p>
<p>强一致性要求任何数据更新在所有副本中立即可见；弱一致性不要求数据更新在所有副本中立即可见，它通过使用一定的规则使所有副本在一定时间内保持相同的状态。根据对分布式环境的分析和 CAP 定理（即在分布式系统中，一致性、可用性和分区容忍度最多只能有两个条件），强一致性导致高延迟和对网络分区的零容忍，弱一致性导致短时间内数据不一致，从而导致应用异常。</p>
<p>因果一致性协议是介于强一致性和弱一致性之间的协议，能够有效解决强一致性带来的高延迟和零分区容忍问题，避免弱一致性带来的应用异常。它满足了分布式环境和 CAP 定理的要求。因果一致性以其独特的优势在分布式存储系统的构建中得到了广泛的应用。</p>
<hr>
<h3 id="napa-powering-scalable-data-warehousing-with-robust-query-performance-at-google"><a class="markdownIt-Anchor" href="#napa-powering-scalable-data-warehousing-with-robust-query-performance-at-google">#</a> 《Napa: powering scalable data warehousing with robust query performance at Google》</h3>
<p>Ankur 等学者（引文：Ankur Agiwal, Kevin Lai, Indrajit Roy,et al. 2021. Napa: powering scalable data warehousing with robust query performance at Google. Proc. VLDB Endow. 14, 12 (July 2021), 2986–2997.）由于 Google 服务不断生成大量数据，同时需要在可扩展性、亚秒级查询响应时间、可用性和强一致性的条件下存储和服务这些数据集的挑战下，开发部署了了一个分析数据管理系统 Napa。Napa 相比 Mesa，Napa 使用物化视图取代了 Mesa 繁琐的刷新技术来加速分析型查询；Napa 将数据新鲜度、成本和查询性能三者根据客户需求进行调整，使需求转换为内部数据库配置，并引入可查询时间戳（Queryable Timestamp，QT）。使用 QT 判断物化视图的延迟度，如图所示，</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/image-20230306162011309-16800541710091.png" alt=""></p>
<p>QT 之前为可查询时间，QT 到 Now（）之间的内容无法查询，[Now（）-QT] 代表增量的数据新鲜度。如果 QT（table）= X，则客户端可以查询在时间 X 之前摄取到表中的所有数据，QT 充当屏障，在 X 之后接收的任何数据都对客户端查询隐藏。一旦在（Y-X）范围内接收的数据被优化以满足查询性能要求，QT 的值将从 X 前进到 Y。QT 在读时使用最小值作为读的时间点，数据库的 QT 是数据库所有表 QT 值的最小值。</p>
<p>例子：本地 QT 值为 100、90、83、75、64 的 5 个 Napa 副本，并且查询服务要求大多数副本可用，则跨所有站点的新 QT 被设置为 83，因为大多数副本至少到 83 为止是最新的。Napa 将使用 QT 至少为 83 的副本来回答查询，因为可以保证对这些副本的查询只需要读取本地可用的增量。</p>
<p>对于提高查询性能，Napa 通过三种技术实现：（1）通过更积极地使用视图，（2）通过改变存储策略，Napa 在存储层提前合并增量，减少查询时增量的数量，并因此减少尾部等待时间，（3）通过解耦摄取、视图维护和查询执行。数据操作在数据中心的每个副本异步执行，而元数据操作定期执行，确保副本之间的数据可用性。Napa 直接使用 F1 作为执行引擎。</p>
<hr>
<h3 id="lazy-maintenance-of-materialized-views"><a class="markdownIt-Anchor" href="#lazy-maintenance-of-materialized-views">#</a> 《Lazy maintenance of materialized views》</h3>
<p>数据库系统通常在基表更新的同一事务中急切地维护视图，这使得视图维护开销很大，Zhou 等学者（引文：Jingren Zhou, Per-Ake Larson, and Hicham G. Elmongui. 2007. Lazy maintenance of materialized views. In Proceedings of the 33rd international conference on Very large data bases (VLDB '07). VLDB Endowment, 231–242.）提出了一种新的惰性维护物化视图的方法，既能减轻视图维护的负担，也能保证查询到最新的视图。惰性维护基本原则：（1）基表更新时，系统不维护视图，只是存储增量信息；（2）系统有空闲周期时，维护由低优先级作业执行；（3）视图在查询时不是最新的，在允许查询访问它之前，该视图被立即维护更新，但仅维护该视图。</p>
<p>如图所示，图中显示惰性视图维护的整体系统设计。</p>
<p>增量表：存储基表的增量流，表中每行有两个附加列（事务序列号和语句序列号）表示哪些事务和语句生成了该增量行。</p>
<p>维护管理器：跟踪维护任务以及生成维护任务并调度，周期性地创建低优先级作业，删除增量表中过时的增量。管理器中包含一个哈希表，以快速寻找给定视图的所有维护任务。</p>
<p>任务表：存储和删除维护任务，仅用于恢复，不做正常处理。</p>
<p>维护任务：由需要维护的视图信息、更新的基表信息、事务序列号、语句序列号、原始事务提交序列号和任务当前状态组成。事务序列号和语句序列号用于惰性维护时定位增量行和基表版本，原始事务提交序列号确定任务维护顺序，任务当前状态用于维护管理器计划和跟踪任务。</p>
<p>当查询开始之前，管理器检查计划使用的视图是否有挂起的维护任务（确保需要使用的视图都是最新的），若存在维护任务，管理器将立即执行这些任务，同时基表上所有的索引立即更新，任务完成后，查询继续执行。如果挂起的维护任务不影响查询访问的视图，则该视图不必立即更新。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/image-20230306162430648-16800542101424.png" alt=""></p>
<p>图为惰性维护和紧急维护在响应时间上的比较。</p>
<p>a、基表更新便立即更新视图，当查询到达时，更新已经全部完成，视图内容为最新的，此时，查询立即完成；</p>
<p>b（1）、基表三次更新 T1、T2、T3 完成后，维护管理器等待系统空闲时，创建低优先级作业完成维护任务，查询到达时，视图是最新的，查询快速完成，查询响应时间与 a 相同；</p>
<p>b（2）、基表完成更新后，视图进行维护时，查询到达，查询等待维护任务完成后继续执行；</p>
<p>b（3）、基表更新完成，查询在系统维护视图之前到达，查询在开始时发出按需维护请求，并等待维护完成，查询继续执行。</p>
<hr>
<h3 id="知识点流处理系统"><a class="markdownIt-Anchor" href="#知识点流处理系统">#</a> 知识点：流处理系统</h3>
<p>（<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/59643962">Stream SQL 的执行原理与 Flink 的实现 - 知乎 (zhihu.com)</a>）</p>
<p>** 流 (Stream)** 可以被看作一种无界 (Unbounded) 且只可追加的 (Append-Only) 的数据表。</p>
<p><strong>流处理系统的时间操作</strong></p>
<p>在现实世界的分布式系统当中处理流主要面对的问题有：</p>
<ol>
<li>绝对时钟 (Absolute Clock) 问题：现实世界当中的时钟往往不精确，而且在分布式系统当中实现时间绝对同步是 (物理上) 不可能的；</li>
<li>时间倾斜 (Time Skew) 问题：由于系统中必然会存在网络延迟、网络中断和系统崩溃等问题， 发送到系统的消息和系统内部的消息很可能失序乃至丢失。</li>
</ol>
<p><strong>解决方案</strong></p>
<p>1. 对于第一个问题，现代操作系统普遍使用事件驱动 (Event-Driven) 模型来处理。通过使用消息本身携带的生成时间 (Event-Time) 而不是系统接收到消息的时间 (Processing Time) 来进行处理。这样的系统当中，时钟是由事件来驱动的。 没有新的事件到来，系统的状态就如同冻结起来了一样。</p>
<p>** 激发器 (Trigger)** 是一类特别的事件，当这种事件的消息被接收到时，某些任务会被激发和执行。</p>
<p>** 水印 (Watermark)** 简单来说，就是根据消息的事件时间来决定一条消息应该被处理还是被丢弃的标记。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/v2-461d11fa37482e48a8bde66a0b91cf2c_r.jpg" alt="v2-461d11fa37482e48a8bde66a0b91cf2c_r"></p>
<p>上图中，从右到左是消息到达的时间，在某时刻，消息 8 通过激发器激发了一次对水印的修改。此时水印的时间限制被修改为 4 。 这意味着之后到达的标号时间小于 4 的消息都会被丢弃。在消息 8 之后到达的消息 7 和 5，虽然时间戳比消息 8 要早， 但是因为仍在 Watermark 的范围里，因此会被考虑在内。最后到达的消息有时间标号 9，他是一条当前观察到过的消息之后的消息， 因此也会被处理。</p>
<p>水印的规则：</p>
<ol>
<li>水印应该永远小于当前处理过的事件的时间戳；</li>
<li>水印是通过激发器的激发来移动的，算子可以自己决定移动水印的时间，而不是每个接收到的事件都会改变水印；</li>
<li>水印必须是单调递增的。否则，一旦水印向前移动，我们无法知道是否已经有被包含在水印范围里的消息被丢弃。</li>
</ol>
<p>** 窗口 (Window)** 是一种设计出来让用户更好地描述它们对时间的需求的工具。 他可以让用户在一个窗口里以有限时间 / 数据范围的方式操作数据，同时也为进一步优化时间空间成本提供了可能。</p>
<p>流处理系统提供的常见的窗口类型有：</p>
<ol>
<li>固定窗口 (Fixed Window)：长度固定的窗口，每个窗口一个紧跟着一个，将时间维度划分成片段；</li>
<li>滑动窗口 (Sliding Window)：长度固定，但每个窗口的开始时间相比于前一个窗口都有一个固定的时间偏移；</li>
<li>会话窗口 (Session Window)：使用事件的属性和相互的时间间隔把他们组织在一个窗口里。这些窗口的开始时间、 持续长度等都会变化。这类窗口用于用户追踪、线索跟踪等场景十分有效。</li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/v2-35d35ee365a77543cc91532e223d5632_r.jpg" alt="v2-35d35ee365a77543cc91532e223d5632_r"></p>
<p>** 窗口和水印是两个不同的概念。** 一个窗口的结束时间已经过去， 并不意味着这个窗口不能再接收迟到的落入这个窗口的消息。实际上，这个窗口的内部状态可以被一直保存， 以便于在接收到新的消息之后刷新窗口内容并输出增量表。一个窗口及其内部状态将只会在水印完全通过之后被回收。 事实上，一个窗口的打开和关闭都有赖于激发器的作用。</p>
<p>** 句点 (Punctation)** 是一些在窗口关闭之前激发的激发器，它使得窗口可以输出它的中间结果而不必等到整个窗口的消息都处理完成。这对于提供低延迟数据传达十分有用。</p>
<p><strong>Stream Join 的语义</strong></p>
<p>由于 Stream 都是无边界的数据，传统数据表当中的 Join 概念在流处理系统当中可能不完全适用。 流处理系统当中的 Join 往往有以下几种类别和语义：</p>
<ol>
<li>Stream 与纯静态表 Join。这里的纯静态表的内容不会改变，因此 Join 的实现只是在 Stream 端对每个消息在静态表内进行查询；</li>
<li>Stream 与动态表的快照 Join。动态表的内容可能会出现增删改等情况，这里的 Join 的语义是， 当对流当中的某个消息实施 Join ，相当于查询了动态表在那一时刻的快照；</li>
<li>Stream 与 Stream Join，操作的两边都是 Stream。</li>
</ol>
<p><strong>动态表与 Stream Join</strong> 则是通过将动态表处理成类似 MVCC 并发控制那样的形式， 因此在每一个来自于 Stream 的消息需要 Join 时，只需要查询对应<strong>事件时间</strong>下动态表的快照即可。</p>
<p>在 Stream Join 动态表这个模型中，动态表这端虽然可能也是由 Stream 而来，但是对动态表的插入和修改操作 (也表示称 Stream 消息) 并不会激发 Join 结果的刷新。 这些消息只是被加入到内部状态中，等待 Stream 里的消息激发刷新时查询。 这是动态表 Join Stream 与 Stream Join Stream 最大的区别。</p>
<p>Stream 与 Stream Join 在两边有消息来的时候都有可能激发大量查询和修改操作，因此面临着严峻的查询放大放大和修改放大问题。在流式处理系统中，一种解决方法是结合窗口语义实现局部的 Join，下图描述了不同窗口下 Join 的语义。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/v2-dac4bd8ff5613358f3fcd04a231c8b31_r.jpg" alt="v2-dac4bd8ff5613358f3fcd04a231c8b31_r"></p>
<hr>
<h3 id="watermarks-in-stream-processing-systems-semantics-and-comparative-analysis-of-apache-flink-and-google-cloud-dataflow"><a class="markdownIt-Anchor" href="#watermarks-in-stream-processing-systems-semantics-and-comparative-analysis-of-apache-flink-and-google-cloud-dataflow">#</a> 《Watermarks in Stream Processing Systems: Semantics and Comparative Analysis of Apache Flink and Google Cloud Dataflow 》</h3>
<p><strong>准备就绪</strong>：对于流处理，准备就绪是指具有可用于产生某个输出的所有必要输入的状态。</p>
<p><strong>健康监测</strong>：由于水位线跟踪整个数据处理管道的进度，因此影响管道进度的任何问题都将表现为水位线中的延迟。假设流处理框架提供了水印的足够细粒度的视图（例如，在管道中的物理阶段之间和内部进行划分），则通常可以通过查找第一个延迟水印来精确定位管道中的问题。</p>
<hr>
<h3 id="convergent-causal-consistency-for-social-media-posts"><a class="markdownIt-Anchor" href="#convergent-causal-consistency-for-social-media-posts">#</a> 《Convergent Causal Consistency for Social Media Posts 》</h3>
<p>异地复制服务在云存储管理中发挥着至关重要的作用，它可以提供增强的可用性、更高的可靠性和更低的延迟，从而按需访问共享基础架构和数据资源。在这样的环境中，一致性对于其中需要对复制的数据进行更新的分布式存储系统是关键的和基本的考虑。收敛因果一致性模型为在线人机交互服务提供了有用的语义，已成为一种流行的一致性模型。自适应非完全复制策略具有降低社交网络系统中消息计数的潜在好处。但是，静态复制对于随时间变化的工作负载效率不高。提出了一个因果 + 一致性协议 CaDRoP，支持自适应动态复制，该协议对帖子后的所有评论具有收敛性，并支持帖子之间的因果排序。根据 Amazon Web Service 的实际价格，采用不同的 PUT 率对 CaDRoP 协议在实际工作负载下进行了评估。结果表明，与在静态复制的数据存储中运行相比，CaDRoP 可以产生明显更低的成本。我们通过将其与透视最优复制解决方案进行比较来进一步评估 CaDRoP。研究结果表明，使用缓存时，CaDRoP 只会产生大约 6% 〜 16% 的额外成本。没有缓存，CaDRoP 在稳定状态下会带来 2% 〜 4.5% 的额外开销。</p>
<hr>
<h3 id="fine-grained-distributed-consistency-guarantees-with-effect-orchestration"><a class="markdownIt-Anchor" href="#fine-grained-distributed-consistency-guarantees-with-effect-orchestration">#</a> 《Fine-grained Distributed Consistency Guarantees with Effect Orchestration 》</h3>
<p>高可用性的分布式应用程序通常需要在地理上分布的存储上复制数据，而这些存储在默认情况下提供的一致性保证较弱。不幸的是，在弱一致性下可能出现不期望的行为，这可能违反应用程序的正确性，迫使设计人员要么实现复杂的特别机制来避免这些异常，要么通过牺牲性能来选择使用更高级别的一致性来运行应用程序。在本文中，我们描述了一个轻量级的运行时系统，它使开发人员不必进行这样的权衡。相反，我们的方法利用了声明性公理规范，这些规范反映了任何正确的实现都必须满足的必要约束，以指导运行时一致性实施和监视机制。实验结果表明，本文提出的细粒度一致性实施机制的性能（可证明是最优的和安全的）优于普通存储提供的一致性保证。</p>
<hr>
<h3 id="simba-tunable-end-to-end-data-consistency-for-mobile-apps"><a class="markdownIt-Anchor" href="#simba-tunable-end-to-end-data-consistency-for-mobile-apps">#</a> 《Simba: Tunable End-to-End Data Consistency for Mobile Apps 》</h3>
<p>云连接移动的应用程序的开发人员需要确保跨多个设备的应用程序和用户数据的一致性。移动的应用程序在各种使用场景下需要不同的分布式数据一致性选择。应用程序还需要优雅地处理间歇性连接和断开、有限的带宽以及客户端和服务器故障。应用程序的数据模型也可能很复杂，跨越相互依赖的结构化和非结构化数据，需要在本地、云和其他移动的设备上以原子方式存储和更新。</p>
<p>在本文中，我们研究了几个流行的应用程序，发现许多应用程序在并发使用时由于数据一致性处理不当而表现出不良行为。针对这些缺点，我们提出了一种新的数据抽象，称为 sTable，它统一了表格和对象数据模型，并允许应用程序从一组分布式一致性方案中进行选择；写入此抽象的移动的应用程序可以毫不费力地与云和其他移动设备同步数据，同时受益于端到端数据一致性。我们构建了 Simba（一个数据同步服务）来演示我们提出的抽象的实用性，并通过编写新应用程序和移植不一致的应用程序来对其进行评估。实验结果表明，Simba 在同步延迟、带宽消耗、服务器吞吐量以及用户数和数据量的伸缩性方面表现良好。</p>
<hr>
<h3 id="viewdf-declarative-incremental-view-maintenance-for-streaming-data"><a class="markdownIt-Anchor" href="#viewdf-declarative-incremental-view-maintenance-for-streaming-data">#</a> 《ViewDF: Declarative incremental view maintenance for streaming data 》</h3>
<p>我们提供 ViewDF：用于物化视图的增量维护的灵活且声明性的框架。该框架的主要组成部分是视图增量函数（ViewDF），它声明性地指定当新的一批数据到达时如何更新物化视图。我们描述并实验评估了一个基于该思想的原型系统，该系统允许用户直接编写 ViewDF，并自动将常见的流查询类转换为 ViewDF。我们的方法概括了增量视图维护的现有工作，并支持流分析中常见的视图的新优化，包括具有模式匹配和滑动窗口的视图。</p>
<hr>
<h3 id="multidirectional-replication-for-supporting-strong-consistency-low-latency-and-high-throughput"><a class="markdownIt-Anchor" href="#multidirectional-replication-for-supporting-strong-consistency-low-latency-and-high-throughput">#</a> 《Multidirectional Replication for Supporting Strong Consistency, Low Latency, and High Throughput 》</h3>
<p>许多复制协议可以用在各种分布式应用中，例如分布式数据库、协作应用和分布式议程，它们牺牲了强一致性以实现更低的延迟和更高的吞吐量。本文描述了单向复制和多向复制的设计、规范、实现和评估，它们挑战了这种不灵活的折衷。通过并行传播结果状态（如在主备份复制中），但使用较少的消息，同时具有处理写请求的头部和处理读请求的尾部（如在链复制中），单向复制改善了两个协议的延迟和吞吐量，而不损害强一致性。为了提高单向复制的计算和通信资源的利用率，多向复制将对象划分为多个逻辑碎片，并在每个逻辑碎片上运行一个单向复制实例。我们已经通过三个步骤完成了提议的协议：（1）将主备复制和链式复制合并为单向复制；（2）将单向复制和逻辑分片合并为多向复制；（3）实施与评价。实验结果表明，与主备复制相比，单向复制在处理具有读写冲突的读请求时，延迟大约降低了 66%; 与链式复制相比，当使用基本设置处理写请求时，单向复制在吞吐量方面显示出大约 59% 的改进；与单向复制相比，多向复制在可处理的客户端数量方面提高了 150%。</p>
<hr>
<h3 id="pgce-a-distributed-storage-causal-consistency-model-based-on-partial-geo-replication-and-cloud-edge-collaboration-architecture"><a class="markdownIt-Anchor" href="#pgce-a-distributed-storage-causal-consistency-model-based-on-partial-geo-replication-and-cloud-edge-collaboration-architecture">#</a> 《PGCE: A distributed storage causal consistency model based on partial geo-replication and cloud-edge collaboration architecture 》</h3>
<p>目前的因果一致性模型难以应对云存储系统中的高同步开销和响应延迟。提出了一种基于部分地理复制和云边缘协作结构的分布式存储因果一致性模型。该模型基于 Cloud-Edge 协作的分布式网络架构，通过哈希函数将云数据集划分为多个子集，并将这些子集存储在靠近用户网络的边缘节点上，实现局部异地复制。同时，通过建立时间戳稳定机制和元数据处理服务，在保证因果关系的前提下实现节点间的数据一致性，降低了元数据处理和数据同步的开销。客户端直接与边缘节点交互，减少了与云 DC 交互的响应延迟。与现有模型相比，PGCE 在响应延迟和吞吐量方面具有更好的性能。</p>
<p>PGCE 的云端可以与已有的因果一致性模式相结合，边缘端的每个节点存储云数据集的一个子集，实现部分地理复制。通过使用副本数据定位矩阵，数据更新仅传播到存储相同数据的节点，从而减少了元数据处理和数据同步开销。客户端的数据请求可以在边缘节点得到及时的处理和响应，减少了直接与云 DC 进行数据交互所带来的延迟。同时，将稳定状态下的数据定期传输到云端进行全局数据的更新和同步。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/image-20230310191238109-168005432929913.png" alt="image-20230310191238109"></p>
<p>图为 PGCE 基于云边缘协作存储架构设计。Cloud 存储客户端写入的所有数据，Edge 由大量靠近用户网络的边缘节点组成，采用部分复制策略存储云数据集的子集，根据节点或 DC 间的存储关系构建点对点 FIFO 数据同步链路。同时，在边缘端设置时间戳稳定机制和元数据处理节点，为客户端提供因果一致的数据存储和查询服务。客户端由许多终端用户组成，可以通过 Migrate 操作（当我们读取的键没有存储在本地节点上时：首先，利用 Hash 函数找到与关键字对应的目标分区。其次，通过矩阵存储关系找到目标分区所在的节点，执行客户端迁移连接到目标节点，实现对非本地节点的数据阅读。）连接到其他边缘节点上，访问本地节点上没有存储的数据。</p>
<p>PGCE 建立了时间戳稳定机制和 Saturn 元数据服务来跟踪因果一致性。在每个 Edge-side 中设置一个 Saturn 节点（元数据处理服务器）。Saturn 节点接收所有需要更新或写入的元数据，并调用 Saturn 接口服务来执行全局因果关系排序，代替在每个边缘节点执行的依赖性检查工作，并以较低的开销确保 PGCE 的因果关系一致性。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/image-20230310192903417-168005435460916.png" alt="image-20230310192903417"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/image-20230310193906414-168005437774019.png" alt="image-20230310193906414"></p>
<p>例子：PGCE 利用矩阵来描述边缘节点和分区（DC) 之间的存储关系。矩阵的行表示分区，列表示节点，元素 1 表示存储该分区的节点，元素 0 表示不存储该分区的节点。从矩阵可以看出，当 P1 被更新时，我们仅将同步消息传播到 Node1 和 Node2，而不传播到 Node3 和 Node4。</p>
<p>基于部分地理复制，每个数据中心存储完整数据集的一个子集，减少了完全地理复制系统的存储、同步和元数据处理开销。</p>
<p><u>基于因果一致性的分布式存储系统，通过<strong>地理复制策略</strong>实现分布在不同位置的 DC 之间的数据同步。地域复制策略主要分为两类：完全异地复制和部分异地复制。在完全异地复制场景中，数据更新需要同步到所有副本，随着数据中心数量的增长，数据同步开销巨大。在部分异地复制方案中，数据更新不需要与所有副本同步，从而减少了同步开销，但这会迫使站点增加远程存储数据项的元数据管理成本。</u></p>
<p><u><strong>边缘计算</strong>是指在靠近事物或数据源头的一侧集成网络、计算、存储、应用等核心能力的开放平台，就近提供服务。它具有低延迟、低宽带操作和隐私保护的优势，这不仅降低了云的负载，还满足了边缘客户端的需求，提供了更好的用户体验。<strong>云计算适用于全局性、非实时性、长周期的大数据处理和分析</strong>。<strong>边缘计算具有实时性、数据安全性和隐私保护等优点，适合于实时、短周期的数据处理和分析</strong></u></p>
<hr>
<h3 id="replicated-data-types-that-unify-eventual-consistency-and-observable-atomic-consistency"><a class="markdownIt-Anchor" href="#replicated-data-types-that-unify-eventual-consistency-and-observable-atomic-consistency">#</a> 《Replicated data types that unify eventual consistency and observable atomic consistency 》</h3>
<p>强一致性广泛应用于关系数据库等系统中。在分布式系统中，强一致性确保所有客户机在所有服务器上原子地观察一致的数据更新。然而，当同步发生时，这样的系统需要牺牲可用性。</p>
<p>我们提出了一个新的一致性协议，可观察原子一致性协议（OACP），使写主导的应用程序尽可能快和一致的需要。OACP 结合了以下优点：（1）可合并的数据类型，具体地说，收敛的复制数据类型，以减少同步，以及（2）可靠的总顺序广播，以提供按需的强一致性。我们还提供了一个高级编程接口，以提高分布式编程的效率和正确性。</p>
<p>本文给出了 OACP 重写逻辑的形式化、机械化模型，并利用模型检测工具 Maude 验证了 OACP 的关键正确性。此外，我们还提供了一个基于 Akka 的 OACP 原型实现，Akka 是一个广泛使用的基于角色的中间件。实验结果表明，与现有的 Raft 一致性协议相比，OACP 协议能够有效降低协调开销。我们的结果还表明，OACP 通过可合并的数据类型提高了可用性，并为实现强一致性提供了可接受的延迟，从而允许有原则地放松强一致性以提高性能。</p>
<hr>
<h3 id="towards-the-synthesis-of-coherencereplication-protocols-from-consistency-models-via-real-time-orderings"><a class="markdownIt-Anchor" href="#towards-the-synthesis-of-coherencereplication-protocols-from-consistency-models-via-real-time-orderings">#</a> 《Towards the Synthesis of Coherence/Replication Protocols from Consistency Models via Real-Time Orderings 》</h3>
<p>本工作集中于具有读写接口的共享存储器系统（例如，分布式数据存储或多处理器）。在这样的系统的核心驻留有负责执行它们的一致性保证的协议。设计一个正确有效地执行一致性的协议是一项非常具有挑战性的任务。我们的总体愿景是自动完成这项任务。在这项工作中，我们通过建立从一致性规范自动推断协议所需的理论基础，朝着这一愿景迈出了一步。具体来说，我们提出了一组数学抽象，称为实时排序（rt 排序），用于对协议进行建模。然后我们创建一个从一致性保证到执行保证的最小 rt - 序的映射。最后，我们非正式地将 rt - 序与协议实现技术联系起来。因此，rt - 排序充当一致性和协议设计之间的中间抽象，其使得能够将一致性保证自动翻译成协议实现。</p>
<hr>
<h3 id="crdts主题"><a class="markdownIt-Anchor" href="#crdts主题">#</a> CRDTs 主题</h3>
<p>无冲突复制数据类型（Conflict-free replicated data type，CRDTs）广泛应用于工业分布式系统，如 Riak 和 AntidoteDB 。它们适合于实现高可用性和可伸缩性的复制共享数据，因为它们支持并发更新，并且如果所有副本最终执行所有更新，则它们保证收敛到相同的状态。</p>
<p>两个主要类别的 CRDTs:<strong> 行动 CRDTs</strong> 和<strong>基于状态的 CRDTs（CvDRT)</strong>。行动 CRDTs 传播交换副本之间的更新操作。他们需要 “完全一次交付”, 这就需要可靠的因果广播。基于状态的 CRDTs, 也叫做 CvRDTs, 传播整个状态之间的 CRDT 副本只要更新状态。交换功能是用于合并多个修正 CRDT 的状态，因此可以发送多次。</p>
<hr>
<h3 id="deepsqueeze-deep-semantic-compression-for-tabular-data"><a class="markdownIt-Anchor" href="#deepsqueeze-deep-semantic-compression-for-tabular-data">#</a> 《DeepSqueeze: Deep Semantic Compression for Tabular Data 》</h3>
<p>大型数据集的快速扩散，高效的数据压缩比以往变得更加重要。柱状压缩技术 (如字典编码，游程编码，增量编码) 表格数据已经证明非常有效，但其通常压缩单个列而不考虑潜在的列之间的关系，如函数依赖和相互关系。语义压缩技术，另一方面，是为了利用这种关系只存储必要列的一个子集来推断，但现有方法不能有效地识别复杂的关系所在列的关系。</p>
<p>DeepSqeeze 是一个新的语义压缩框架，通过使用自动编码器将元组映射到低维空间，捕获表格数据中分类列和数值列之间的复杂关系。DeepSqeeze 还支持数值数据有损压缩的保证误差范围，并与常见的列式压缩格式结合使用。</p>
<p><strong>通用压缩算法</strong>忽略了数据集的高级语义，只对原始比特进行操作。这些技术分为两类：（1）无损和（2）有损。</p>
<p>无损压缩是可逆的，这意味着原始输入可以从压缩格式完美恢复。无损压缩算法通常通过识别和去除输入数据中的统计冗余来操作。例如，霍夫曼编码 [24] 用可变长度代码替换符号，将较短的代码分配给更频繁的符号，使得它们需要更少的空间。</p>
<p>有损压缩，与无损压缩不同。有损压缩通过丢弃不必要的信息（例如截断测量值的最低有效位或对图像进行二次采样）来减小数据大小。由于信息的丢失，该过程是不可逆的。虽然一些用例需要输入的完美可恢复性（例如，银行交易），DeepSqueeze 工作集中在通常可以容忍不同程度的丢失的数据存档场景。</p>
<p><strong>DeepSqeeze 是第一个将自动编码器应用于表格数据的语义压缩方法</strong>。重要的是，DeepSqeeze 可以捕获分类列和数值列之间的复杂关系，并且我们通过用户指定的错误阈值将数值的损失纳入模型中。DeepSqeeze 使用自动编码器将元组映射到低维空间，允许对许多列之间的复杂关系进行建模。</p>
<h4 id="deepsqeeze的压缩过程"><a class="markdownIt-Anchor" href="#deepsqeeze的压缩过程">#</a> DeepSqeeze 的压缩过程</h4>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/image-20230403183001601.png" alt="image-20230403183001601"></p>
<h5 id="预处理"><a class="markdownIt-Anchor" href="#预处理">#</a> 预处理</h5>
<p>作为输入，DeepSqeeze 接受一个表格数据集，该数据集由分类列和数值列的任意组合以及指定列类型的元数据组成。</p>
<p>预处理将此输入数据预处理为模型可以操作的格式。根据数据类型，应用各种转换（例如，字典编码），以及遵守数值列的指定误差阈值的量化版本。</p>
<p>以下为每种列类型的不同预处理技术：</p>
<p>1. 分类列</p>
<p>分类列包含不同的、无序的值，通常表示为字符串。对于具有很少不同值的列，字典编码是一种普遍的压缩技术，它涉及用较小的代码替换较大的数据类型。DeepSqeeze 将分类列中的每个非重复值替换为唯一的整数代码，产生两个用途：（1）已经减小了输入数据的大小；（2）将分类值转换为模型所需的数值类型。例如，DeepSqeeze 将分别用 {0，1，2，3} 替换列中的值 {A，B，C，D}。</p>
<p>另一方面，对于具有许多不同值的分类列（例如，唯一字符串，主键），DeepSqeeze 会自动将它们从正常的压缩管道中排除，并回撤到现有的压缩技术。然而，在值的分布偏斜的特定情况下，在训练期间可以忽略不频繁出现的值，使得仅在最频繁出现的分类值上训练模型。由于减少分类列的可能输出值的数量可以显著减少模型中的参数数量，因此与错误预测不常见值相关的少量额外开销会被模型大小的大幅减少所抵消。</p>
<p>2. 数字列</p>
<p>数值列可以包含整数或浮点数。在这两种情况下，第一步都是执行最小最大缩放，将所有值归一化到 [0，1] 范围，这将为模型训练准备数值列，并解决列值之间的缩放差异。</p>
<p>然而，许多应用可以容忍某种程度的不精确性，因为它们不需要精确的结果（例如，视觉数据探索），或者因为在数据生成过程中存在一些其它形式的噪声（例如，传感器硬件的限制）。因此，还将允许用户为每列指定错误阈值与有损压缩进行有效结合。允许有损压缩的一种方式是通过接受指定误差阈值内的值的任何预测来扩展无损版本。此外，我们必须修改相关的损失函数以考虑错误阈值，这样模型就不会惩罚正确的预测。</p>
<p>替代方法是量化列，其涉及用使用指定误差阈值计算的不相交桶的中点替换值。例如，考虑一个数值列，其值在 [0，100] 范围内，用户指定的错误阈值为 10%; 我们的量化方法将用离散桶中点替换这些连续值：{10，30，50，70，90}。由于量化已经将误差阈值合并到桶创建中，因此我们不需要修改模型或损失函数。</p>
<p>与第一种方法相比，量化允许模型学习离散映射，这具有两个主要优点：（1）模型可以简单得多，因此尺寸更小；（2）离散值更容易预测，导致更少的物化故障。此外，针对量化值的具体化故障的列压缩比连续值有效得多。</p>
<h5 id="模型构建"><a class="markdownIt-Anchor" href="#模型构建">#</a> 模型构建</h5>
<p>构建一个自动编码器的人工神经网络，它将预处理的输入数据映射到低维表示。自动编码器类似于其他降维技术，但它们能够同时跨多个列学习复杂的关系。无监督训练过程在数据集上迭代进行，直到收敛。重要的是，与传统的机器学习设置不同，我们的<strong>目标是将模型过拟合到输入数据，以最小化压缩输出的大小</strong>。将模型过拟合到训练数据的一种方式是创建能够捕获数据集中的所有关系的复杂模型，而替代方法涉及构建多个更简单的模型，称为<strong>专家混合</strong>，其专门用于包含相似元组的数据的某些分区。图中显示了三个专门的模型，元组通过一个阀门路由到模型，该模型在训练期间学习数据的最佳划分。</p>
<p>下图描绘了用于压缩具有一个分类（C）列和三个数值（N）列的数据集的示例自动编码器。如图所示，自动编码器由两个几乎对称的模型组成：（1）编码器，其将输入元组映射到低维空间；以及（2）试图重构输入元组的解码器。共享中间层表示每个元组的学习表示（代码）。DeepSqeeze 总是用比原始输入元组更小的表示层来构造自动编码器，这是将数据映射到低维空间的瓶颈。DeepSqeeze 存储这些代码，并在解压缩期间使用解码器重新创建元组。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/image-20230403200107007.png" alt="image-20230403200107007"></p>
<p>为了处理现实世界数据集中经常出现的混合分类列和数值列，DeepSqeeze 需要基于列类型信息动态调整基本自动编码器架构。图中的数值列在输出层中只需要一个节点，而分类列则需要为每个不同的值指定一个节点。在上一个示例中，具有可能值 {A，B，C，D} 的分类列需要四个输出节点（图中的蓝色）。</p>
<p>与集成分类列相关的关键问题之一是在最终完全连接层中引入大量连接所导致的模型大小的潜在爆炸。为了解决这个问题，使用<strong>参数共享技术</strong>，涉及所有分类列的共享输出层，而不是每列每个不同值的单个节点。<strong>共享输出层的大小由任何分类列中不同值的最大数目来限定</strong>。同时，还必须在输出层之前添加一个辅助层，每个分类列有一个节点，以及一个额外的信号节点。信号节点简单地为每个分类列提供索引，通知共享层如何解释来自特定输出的辅助层的值。</p>
<p>下图描述数据集解码器的最后两层，该数据集具有三个分类列，分别用于传统架构（左）和参数共享版本（右）。每列都有不同数量的不同值，这些值是用颜色编码的。由于数据集有三列，我们的辅助层包含三个节点加上一个信号节点 s。共享输出层有五个节点，这是所有列中不同值的最大数量。如图所示，辅助层显著减小了完全连接层的尺寸。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/image-20230403201110277.png" alt="image-20230403201110277"></p>
<p><u>专家混合</u></p>
<p><strong>构建几个较小且不太复杂的模型来处理不相交的数据子集</strong>。这种方法是，每个较小的模型可以学习一组有限的简单映射。</p>
<p>本文使用了一个稀疏门控的专家混合体，它学习如何以无监督的方式而不是传统的聚类算法来最好地划分数据集。该体系结构的核心是一个门，它是一个独立的模型，将元组分配给最适合的专家（即，对于每个元组具有最高精度的模型）。因此，门需要每个专家一个输出。</p>
<p>具体过程：由图 1 所示，将每个输入元组分配给三个专家中的一个。然而，在实践中，输入元组被同时馈送给所有专家，并且门为除了所选择的专家的预测之外的所有专家产生掩码。</p>
<p>与代码大小类似，专家数量是一个超参数，必须根据具体情况进行选择。使用太少的专家将导致模型精度差，而太多的专家将不必要地增加模型的大小。</p>
<h5 id="物化"><a class="markdownIt-Anchor" href="#物化">#</a> 物化</h5>
<p>物化使用经过训练的自动编码器来生成低维表示，在图中标记为 Codes。这些代码中的每一个表示单个元组，并且在大小上比原始元组小得多。同时，还必须保存模型的解码器部分，以便从代码中重建原始元组，以及从我们的模型中纠正错误预测（用 X 表示）的失败值。</p>
<p>物化解码器通常表示总体压缩输出大小的相对小的部分，这表明优化的资源消耗将更好地花费在其他地方（例如，减小具体化故障的大小）。</p>
<p>对于代码物化，模型产生最小宽度为 64 位的代码（即，双精度浮点值），但 64 位通常较大。因此，<strong>DeepSqeeze 迭代地截断每个代码，直到代码大小的减少不再支付相应的失败数量的增加</strong>。由于浮点值通常难以压缩，因此在截断之后将代码转换为整数的最后步骤可以进一步减小大小。对于这种优化，我们将代码乘以通常所需的最小幂，以确保具有最大小数位数的代码转换为整数，然后将结果转换为整数类型，然后可以使用标准整数压缩技术（例如，增量编码）。</p>
<p>物化故障：故障的物化代表压缩输出大小的最大部分。本文使用 Parquet 来压缩物化故障。</p>
<h4 id="解压缩"><a class="markdownIt-Anchor" href="#解压缩">#</a> 解压缩</h4>
<p>解压缩过程基本上执行压缩过程中每个步骤的逆过程。具体地，解压缩流水线通过将物化代码传送到所保存的解码器，解码器重构出与预处理输出结果的近似版本。然后，将每个重建的元组与具体化的故障进行比较，并将所有错误值替换为正确值。在反转预处理的最后一步之后，已经恢复了原始数据集。</p>
<p>专家映射：对于具有单个专家的模型，使用单个解码器来解压缩所有元组。然而，对于具有多个专家的模型，需要物化将代码映射到正确解码器的元数据。本文考虑两种方式存储这些映射：</p>
<p>第一种方法如图 1 所示，其中代码和故障由专家分组，并与其原始索引沿着存储。这些索引告诉 DeepSqeeze 重建原始文件的顺序，并且它们通常可以通过 delta 编码进行有效压缩。</p>
<p>第二种方法涉及存储所有元组以及每个元组的附加专家分配标签，然后 DeepSqeeze 可以使用该标签来选择正确的解码器。与存储索引类似，这些标签通常可以使用行程长度编码进行有效压缩。</p>
<p>在这两个备选方案之间作出选择取决于数据，因此必须根据具体情况作出选择。对于不必在原始数据集中保持元组的确切顺序，例如关系表。我们可以通过使用第一种方法来保存额外的空间，该方法存储按专家分组的元组，而无需物化索引。</p>
<hr>
<h3 id="f1-query-declarative-querying-at-scale"><a class="markdownIt-Anchor" href="#f1-query-declarative-querying-at-scale">#</a> 《F1 Query: Declarative Querying at Scale》</h3>
<h4 id="动机"><a class="markdownIt-Anchor" href="#动机">#</a> 动机</h4>
<p>在类似 Google 这样的大型企业中，数据处理和分析在数据大小、延迟、数据源和新鲜度以及对自定义业务逻辑的需求方面有不同的需求。许多数据处理系统仅仅专注于该需求功能的特定情况，例如，专注于事务式查询、中型 OLAP 查询的提取 - 转换 - 加载（ETL）管道。有些系统是高度可扩展的，而有些则不是。有些系统主要作为一个封闭的筒仓运行，而其他系统可以轻松地从其他来源提取数据。有些系统查询实时数据，但有些系统必须先摄取数据，然后才能高效地查询数据。</p>
<h4 id="优势"><a class="markdownIt-Anchor" href="#优势">#</a> 优势</h4>
<p>F1 Query，是一个 SQL 查询引擎，它的优势并不在于它专注于做好一件事，而是它的目标是覆盖企业数据处理和分析需求空间的各个角落。F1 Query 模糊了事务性、交互式和批处理工作负载之间的传统区别，支持以下功能：（i）仅影响少数记录的 OLTP 点查询，（ii）大量数据的低延迟 OLAP 查询，以及（iii）将来自不同来源的数据转换和混合到支持复杂分析和报告工作负载的新表中的大型 ETL 管道。F1 Query 还通过支持与自定义业务逻辑集成的声明性查询，大大减少了开发硬编码数据处理管道的需求。因此，F1 是一个通用的查询系统，可以支持企业数据处理和分析的绝大多数用例。</p>
<ul>
<li>
<p>数据中心框架</p>
<p>F1 Query 是为数据中心而不是单个服务器或紧密耦合的集群构建的。传统的无共享数据库管理系统试图将数据的计算和处理始终保持在数据所在的位置。此外，经典范例将数据库存储子系统与查询处理层紧密耦合，通常共享内存管理、存储布局等。相比之下，F1 Query 将数据库存储与查询处理分离，因此，它可以作为数据中心中所有数据的引擎，在很大程度上消除了访问本地与远程数据时的吞吐量和延迟差异。</p>
</li>
<li>
<p>可伸缩性</p>
<p>客户端的需求差异很大，不仅在被处理的数据集的大小方面，而且在延迟和可靠性要求以及允许的资源成本方面。在 F1 Query 中，短查询在单个节点上执行，而较大的查询在低开销的分布式执行模式下执行，没有检查点和有限的可靠性保证。最大的查询以可靠的面向批处理的执行模式运行，该模式使用 MapReduce 框架。在这些模式中的每一种模式中，F1 Query 通过增加用于查询处理的计算并行性来减轻大数据大小的高延迟。</p>
</li>
<li>
<p>可扩展性</p>
<p>客户端能够使用 F1 Query 来满足任何数据处理需求，包括那些在 SQL 中不容易表达或需要访问新格式数据的需求。为了满足这一需求，F1 Query 具有高度的可扩展性。它支持用户定义函数（UDF）、用户定义聚合函数（UDA）和表值函数（TVF），以便将用本机代码编写的复杂业务逻辑集成到查询执行中。</p>
</li>
</ul>
<h4 id="f1查询架构的概述"><a class="markdownIt-Anchor" href="#f1查询架构的概述">#</a> F1 查询架构的概述</h4>
<p>![F1 overview](/images/F1 overview.png)</p>
<h5 id="架构"><a class="markdownIt-Anchor" href="#架构">#</a> 架构</h5>
<p>图 1 描述了单个数据中心内的基本架构和组件之间的通信。用户通过 F1 Query 的客户端库与 F1 Query 进行交互，该库将请求发送到几个专用服务器中的一个（称为 F1 服务器）。F1 主站是数据中心内的专用节点，负责查询执行的运行时监控，并维护该数据中心的所有 F1 服务器。小型查询和事务开始在接收请求的直接 F1 服务器上执行。F1 通过在 worker 池中的 worker 上动态地提供执行线程来调度用于分布式执行的较大查询。最大的查询被安排在使用 MapReduce 框架的批处理执行模式中执行。最终结果在 F1 服务器上收集，然后返回给客户端。F1 服务器和 worker 通常是无状态的，允许客户端每次与任意 F1 服务器通信。由于 F1 服务器和工作器不存储数据，因此添加新的 F1 服务器或工作器不会触发任何数据重新分配成本。因此，数据中心的 F1 Query 部署可以通过添加更多服务器或工作器轻松地向外展。</p>
<h5 id="查询执行"><a class="markdownIt-Anchor" href="#查询执行">#</a> 查询执行</h5>
<p>用户通过其客户端库与 F1 Query 交互。客户端的查询请求可能到达许多 F1 服务器中的一个。在到达 F1 服务器时，F1 服务器首先解析和分析 SQL 查询，然后提取查询访问的所有数据源和接收器的列表。如果任何数据源或接收器在本地数据中心中不可用，并且在更靠近数据源或接收器的其他数据中心处存在 F1 服务器，则 F1 服务器将查询连同关于可用于运行查询的最佳数据中心集的信息发送回客户端。然后，客户端将查询重新发送到目标数据中心的 F1 服务器以供执行。可以注意到，虽然存储和计算的分解以及高性能网络结构已经消除了数据中心内的许多局部性问题，但是从一组许多地理上分布的数据中心中选择接近数据的数据中心仍然对查询处理延迟具有很大的影响。</p>
<p>在 F1 服务器上，查询执行从规划阶段开始，在规划阶段中，优化器将分析的查询抽象语法树转换为关系代数运算符的 DAG，然后在逻辑和物理级别上对其进行优化。然后将最终的执行计划移交给执行层。根据客户端指定的执行模式首选项，F1Query 以交互模式或批处理模式（使用 MapReduce 框架）在 F1 服务器和 worker 上执行查询，如图 2 所示。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/image-20230828161456746.png" alt="image-20230828161456746"></p>
<p>对于交互式执行，查询优化器应用启发式方法在单节点集中式执行和分布式执行之间进行选择。在集中式执行中，服务器在接收查询的第一个 F1 服务器上立即分析、规划和执行查询。在分布式模式下，接收查询的第一个 F1 服务器仅充当查询协调器。该服务器调度单独的 worker 上的工作，然后这些 worker 一起执行查询。交互式执行模式为中小型查询提供了良好的性能和资源高效的执行。</p>
<p>批处理模式为处理大量数据的长时间运行的查询提供了更高的可靠性。F1 服务器将在批处理模式下运行的查询的计划存储在单独的执行存储库中。批处理模式分发和调度逻辑使用 MapReduce 框架异步运行查询。在此模式下执行查询可以容忍服务器重新启动和故障。</p>
<h5 id="数据来源"><a class="markdownIt-Anchor" href="#数据来源">#</a> 数据来源</h5>
<p>数据中心的 F1 服务器和 worker 不仅可以访问它们所在的数据中心中的数据，还可以访问任何其他 Google 数据中心中的数据。处理和分析存储层使得能够从各种来源检索数据，从 Spanner 和 Bigtable 等分布式存储系统到具有不同结构的普通文件，如逗号分隔值文本文件（CSV），面向记录的二进制格式和压缩列式文件格式，如 ColumnIO 和 Capacitor 。F1 Query 为支持它的数据源提供一致和可重复的读取，包括 Spanner 存储服务管理的数据。</p>
<p>为了支持对异构数据源的查询，F1 Query 抽象了每种存储类型的详细信息。它使所有数据看起来就像是存储在关系表中一样，并允许连接存储在不同来源中的数据。它使用全局编录服务来维护和检索有关以不同格式和系统存储的数据源的元信息。F1 查询还允许查询通过全局编录服务不可用的源。在这种情况下，客户端必须提供一个 DEFINE TABLE 语句，该语句描述如何将底层数据源表示为关系数据库表。下面展示了一个从 CSV 格式的 Colossus 文件中检索数据的示例。F1 查询必须知道文件的位置和类型以及其中包含的列的名称和类型。注意，不同的数据源可能需要不同的信息来描述其结构，这取决于其独特的属性。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/image-20230828162323322.png" alt="image-20230828162323322"></p>
<p>虽然 F1 Query 原生支持 Google 中最广泛使用的数据源，但客户端偶尔需要通过事先未知的机制访问数据。为此，F1 支持使用名为表值函数（TVF）的扩展 API 添加新的自定义数据源，在后面章节中有更详细的描述。</p>
<h5 id="数据下移"><a class="markdownIt-Anchor" href="#数据下移">#</a> 数据下移</h5>
<p>查询的输出可以返回给客户端，但是查询也可以请求将其输出存储到外部数据接收器中。接收器可以包括各种格式的文件或以其他方式使用各种远程存储服务。与数据源一样，接收器可以是由编录服务管理的表，也可以是手动指定的目标。托管表由 CREATE TABLE 语句创建。默认情况下，它们作为存储在 Colossus 文件系统中的文件实现。手动指定的存储目标是使用 EXPORT DATA 语句指定的，使用的规范类似于用于阅读回相同数据的相应 DEFINE TABLE 规范。除了这些选项之外，查询还可以创建会话本地临时表。</p>
<h5 id="查询语言"><a class="markdownIt-Anchor" href="#查询语言">#</a> 查询语言</h5>
<p>F1 Query 符合 SQL 2011 标准，具有支持查询嵌套结构化数据的扩展。F1 Query 支持标准 SQL 功能，包括左 / 右 / 完全外部联接、聚合、表和表达式子查询、WITH 子句和分析窗口函数。对于结构化数据，F1 Query 支持可变长度的 ARRAY 类型，以及 STRUCs，这些类型与 SQL 标准行类型很相似。F1 Query 还支持 Protocol Buffers [9]，这是一种在 Google 广泛使用的结构化数据交换格式。</p>
<h4 id="执行内核和交互式执行模式"><a class="markdownIt-Anchor" href="#执行内核和交互式执行模式">#</a> 执行内核和交互式执行模式</h4>
<p>默认情况下，F1 Query 以称为交互式执行的同步联机模式执行查询。F1 查询支持两种类型的交互式执行模式：集中式和分布式。在规划阶段，优化器分析查询并确定是以集中模式还是分布式模式执行。在集中式模式下，当前 F1 服务器使用单个执行线程立即执行查询计划。相反，在分布式模式下，当前 F1 服务器充当查询协调器。它将工作安排在称为 F1 工作进程的其他进程上，然后这些进程一起并行执行查询。在本节中，我们将详细描述 F1 查询交互式执行。</p>
<h5 id="单线程执行内核"><a class="markdownIt-Anchor" href="#单线程执行内核">#</a> 单线程执行内核</h5>
<p>图 3 描述了一个 SQL 查询和用于集中式模式执行的结果查询计划。在这种模式下，F1 Query 使用单线程执行内核。图 3 所示的矩形框是执行计划中的运算符。单线程执行使用基于递归拉取的模型以 8 KiB 的批量处理元组。执行运算符递归地调用基础运算符上的 GetNext（），直到叶运算符检索到批量元组。叶子通常是从数据源读取的 Scan 运算符。每个数据源都有自己的扫描运算符实现，其特征集取决于数据源的类型。一些源仅允许全表扫描，而其他源也支持基于键的索引查找。一些源代码还支持在非键字段上下推简单筛选表达式。一个单独的 ARRAY 扫描运算符根据需要从数组类型的表达式中生成行。对于可能包含协议缓冲区的输入数据，所有扫描操作符都支持立即在数据源扫描节点处进行协议缓冲区解码，从而确保执行器不会传递大的编码协议缓冲区团块，除非它们全部被需要。相反，每个扫描操作符立即提取查询所需的最小字段集。F1 Query 还支持几个高性能的列数据源，这些数据源分别存储协议缓冲区或 SQL 结构的字段，并且根本不需要任何协议缓冲区解码。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/image-20230828164255793.png" alt="image-20230828164255793"></p>
<p>F1 查询支持多种连接操作符，包括查找连接（索引嵌套循环连接）、散列连接、合并连接和数组连接。hash join 操作符实现了一个多级递归混合 hash join，并将磁盘溢出到 Colossus 分布式文件系统。查找连接操作符从其左输入读取包含键的行，并使用这些键在其右输入（必须是扫描操作符）上执行索引查找。合并联接运算符合并共享相同排序顺序的两个输入。F1 Query 还有一个针对 Spanner 表的集成扫描 / 连接操作符，它对来自基础表的数据流实现合并连接。数组连接是数组扫描的相关连接，其中数组表达式引用连接的左输入，在 SQL 查询中写为数组值表达式 f（）的 T JOIN UNNEST（f（T））。</p>
<p>除了扫描和连接之外，F1 Query 还有投影、聚合（基于排序和磁盘溢出）、排序、联合和分析窗口函数的运算符。所有执行操作符（包括扫描和联接）都内置支持，用于在其输出行上应用筛选谓词以及 LIMIT 和 OFFSET 操作。</p>
<h5 id="分布式执行"><a class="markdownIt-Anchor" href="#分布式执行">#</a> 分布式执行</h5>
<p>当优化器检测到分布式执行计划最适合使用分区读取以高并行度扫描输入表时，它会生成这样的计划。在这种情况下，查询执行计划被分割成查询片段，如图 4 所示。每个片段在一组 F1 工作节点上调度。这些片段同时执行，同时具有流水线和浓密并行性。工作节点是多线程的，并且一些工作节点可以执行同一查询的多个独立部分。</p>
<p>优化器采用自底向上的策略，根据查询计划中每个操作符的输入分布要求计算计划片段边界。每个单独的操作者可以具有跨工作者分发其输入数据的要求。如果存在，则通常在一些字段集合上对需求进行散列。典型的示例包括用于聚合的分组键或用于散列联接的联接键。当这个需求与输入操作符的元组分布兼容时，优化器将两个操作符都计划在同一个片段中。否则，它计划两个操作符之间的交换操作符以生成片段边界。</p>
<p>下一步是为每个片段选择并行 worker 的数量（参见图 4）。片段以独立的并行度操作。叶运算符的表扫描中的底层数据组织确定初始并行化，并具有上限。然后，宽度计算器递归地将该信息向上传播到查询计划树。例如，一个 50 个 worker 片段和一个 100 个 worker 片段之间的散列连接将使用 100 个 worker 来执行，以适应两个输入中较大的一个。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/image-20230828165230110.png" alt="image-20230828165230110"></p>
<p>以下查询说明了分布式执行：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/image-20230828165308940.png" alt="image-20230828165308940"></p>
<p>此查询涉及两个表：Ads 是一个用于存储广告信息的 Spanner 表，而 Clicks 是一个存储广告点击的表，定义在 Google 的分析数据仓库 Mesa 中。此查询查找在 Chrome OS 上发生的所有广告点击，广告开始日期在 2018-05-14 之后。然后，它聚合符合条件的元组以查找每个区域的点击，并按点击次数的降序。</p>
<p>此查询的一个可能计划如图 5 所示。在执行期间，数据流自下而上通过每个操作符，直到到达聚合和排序操作符。一千个工作进程中的每一个都扫描 Clicks 表中的数据。查询规划器将过滤器 Clicks.OS = 'ChromeOS’下推到 Mesa 扫描本身中，以便仅将满足过滤器的行从 Mesa 返回到 F1 worker。200 名工作人员使用过滤器 Ads 处理 Ads 表的扫描。StartDate &gt; ‘2018-05- 14’。来自两次扫描的数据流入一个散列连接运算符，然后同一个 F1 工作进程对连接结果执行部分聚合。最后，F1 服务器执行完整的聚合，并将排序后的输出返回给客户端。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/image-20230828165933726.png" alt="image-20230828165933726"></p>
<h5 id="分区策略"><a class="markdownIt-Anchor" href="#分区策略">#</a> 分区策略</h5>
<p>在分布式执行模式下，F1 Query 并行执行多个片段。执行和数据流可以被视为 DAG，如图 4 所示。数据通过使用交换操作符进行重新分区而跨每个片段边界移动。对于每个元组，发送方应用分区函数来确定该元组的目的地分区。每个分区号对应于目的地片段中的特定 worker。</p>
<p>交换操作使用从每个源片段分区到所有目的地片段分区的直接远程过程调用（RPC，简称 RPC）来实现，其中每个发送方和接收方之间具有流控制。这种基于 RPC 的通信模式可以很好地扩展到每个片段数千个分区。需要更高并行度的查询通常以批处理执行模式运行。F1 Query 的交换操作符在数据中心本地运行，利用 Google 的 Jupiter 网络。Jupiter 允许由数万台主机组成的集群中的每台服务器与同一集群中的任何其他服务器进行通信，其持续带宽至少为 10 Gb/s。</p>
<p>查询优化器将每个扫描操作符规划为查询执行计划中的叶沿着期望的 N 个工作器并行性。为了以并行化的方式执行扫描，工作必须被分布，以便每个扫描工作器产生元组的不重叠子集，并且所有工作器一起产生完整的输出。然后，查询调度程序要求扫描操作符将其自身划分为 N 个分区。作为响应，扫描操作器产生 N 个或更多个分区描述。为了实现这一点，调度器然后调度计划的副本以在 N 个工作器上运行，并向每个工作器发送先前获得的分区描述中的一个。然后，每个工作器产生由其分区描述的数据子集。在一些情况下，分区的实际数量（例如，基于文件的表的数据文件的数量）可能超过 N，在这种情况下，查询执行器随时间动态地将分区分配给可用的工作者。这种方法避免了由偏斜引起的扫描的长尾延迟。</p>
<p>一些操作符在与其输入之一相同的计划片段中执行。例如，查找连接在与其左输入相同的片段中执行，仅处理由该输入的相同分区产生的元组的查找。相反，如图 5 所示，散列连接的执行通常需要多个片段，每个片段具有多个分区。查询优化器将每个输入扫描操作符（或其他子计划）计划在单独的片段中，除非输入操作符的数据分布已经与散列联接键兼容。这些源片段（图 5 中的 SCAN 点击和 SCAN 广告）中的每一个将其数据发送到包含散列连接操作符的相同目的地片段（图 5 中的右侧所示）。两个输入片段都使用基于联接键的散列的相同分区函数来发送它们的数据。这确保了具有相同联接键的所有行最终在相同的目标分区中，从而允许每个散列联接分区针对键空间的特定子集执行联接。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/image-20230828170121934.png" alt="image-20230828170121934"></p>
<p>聚合操作符通常还需要重新分区。对于具有分组键的聚合，查询计划通过分组键的散列重新划分输入元组，并且使用聚合操作符将这些元组发送到目的地片段。对于没有分组键的聚合，所有元组都被发送到单个目的地。图 5 包含了一个没有分组键的聚合示例。如图所示，通过在执行尽力而为存储器中部分聚合的交换操作符之前添加第二聚合操作符来优化聚合。这减少了传输的数据量，并且对于具有分组密钥的聚合，其减轻了在目的地片段处的完全聚合期间热分组密钥的不利影响。</p>
<p>如前所述，F1 中的执行计划是 DAG 形状的，可能具有多个根。对于数据流 DAG 中的分叉，计划片段重新划分为多个目的片段，每个目的片段具有不同的划分功能。这些 DAG fork 为 SQL WITH 子句和由优化器消除重复数据的相同子计划实现 run-once 语义。DAG 分叉还用于其他复杂的计划，例如，分析函数和 DISTINCT 输入上的多个聚合。DAG 分叉对消费者片段中不同的数据消费速度敏感，以及如果多个分支在稍后再次合并时阻塞，则对分布式死锁敏感。示例包括来自 DAG 分叉的自散列连接，其尝试在构建阶段初始消耗所有元组。实现 DAG 分叉的 Exchange 操作符通过在内存中缓冲数据，然后在所有消费者被阻止时将数据溢出到 Colossus 来解决这些问题。</p>
<h5 id="性能注意事项"><a class="markdownIt-Anchor" href="#性能注意事项">#</a> 性能注意事项</h5>
<p>F1 Query 中查询性能问题的主要原因包括不对称和次优的数据源访问模式。散列连接可能对来自两个输入的热键特别敏感。加载到哈希表（构建输入）的输入中的热键可能导致溢出，因为一个 worker 将需要比其他 worker 存储更多的元组。其他输入（探测输入）中的热键可能会产生 CPU 或网络瓶颈。对于一个输入足够小以适合内存的情况，F1 Query 支持广播散列连接，该散列连接读取小的构建输入并将所有结果元组的副本广播到所有散列连接工作器。然后，每个 worker 构建哈希表的相同副本。此广播散列联接对偏斜不敏感，尽管它对意外的大生成输入敏感。</p>
<h4 id="基于mapreduce的批处理执行模式"><a class="markdownIt-Anchor" href="#基于mapreduce的批处理执行模式">#</a> 基于 MapReduce 的批处理执行模式</h4>
<h4 id="f1查询优化器"><a class="markdownIt-Anchor" href="#f1查询优化器">#</a> F1 查询优化器</h4>
<h4 id="f1中的各种扩展性选项"><a class="markdownIt-Anchor" href="#f1中的各种扩展性选项">#</a> F1 中的各种扩展性选项</h4>
<h4 id="f1的结构化数据处理"><a class="markdownIt-Anchor" href="#f1的结构化数据处理">#</a> F1 的结构化数据处理</h4>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://chendouxing.github.io">蟹堡王海星</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://chendouxing.github.io/2023/03/28/%E8%AE%BA%E6%96%87/">https://chendouxing.github.io/2023/03/28/%E8%AE%BA%E6%96%87/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://chendouxing.github.io" target="_blank">蟹堡王海星</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87/">论文</a></div><div class="post_share"><div class="social-share" data-image="https://img1.imgtp.com/2023/08/24/0Jp2Kj9v.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-full"><a href="/2023/03/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%89%E7%BA%A7%E8%80%83%E8%AF%95/" title="计算机三级填空题"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img1.imgtp.com/2023/08/24/ntzFO2LW.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">计算机三级填空题</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">蟹堡王海星</div><div class="author-info__description">花有重开日，人无再少年</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">5</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">11</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/chendouxing/chendouxing.github.io.git" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:2411302260@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E7%9F%A5%E8%AF%86%E7%82%B9"><span class="toc-number">1.</span> <span class="toc-text"> 数据一致性知识点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#napa-powering-scalable-data-warehousing-with-robust-query-performance-at-google"><span class="toc-number">2.</span> <span class="toc-text"> 《Napa: powering scalable data warehousing with robust query performance at Google》</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#lazy-maintenance-of-materialized-views"><span class="toc-number">3.</span> <span class="toc-text"> 《Lazy maintenance of materialized views》</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B5%81%E5%A4%84%E7%90%86%E7%B3%BB%E7%BB%9F"><span class="toc-number">4.</span> <span class="toc-text"> 知识点：流处理系统</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#watermarks-in-stream-processing-systems-semantics-and-comparative-analysis-of-apache-flink-and-google-cloud-dataflow"><span class="toc-number">5.</span> <span class="toc-text"> 《Watermarks in Stream Processing Systems: Semantics and Comparative Analysis of Apache Flink and Google Cloud Dataflow 》</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#convergent-causal-consistency-for-social-media-posts"><span class="toc-number">6.</span> <span class="toc-text"> 《Convergent Causal Consistency for Social Media Posts 》</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#fine-grained-distributed-consistency-guarantees-with-effect-orchestration"><span class="toc-number">7.</span> <span class="toc-text"> 《Fine-grained Distributed Consistency Guarantees with Effect Orchestration 》</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#simba-tunable-end-to-end-data-consistency-for-mobile-apps"><span class="toc-number">8.</span> <span class="toc-text"> 《Simba: Tunable End-to-End Data Consistency for Mobile Apps 》</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#viewdf-declarative-incremental-view-maintenance-for-streaming-data"><span class="toc-number">9.</span> <span class="toc-text"> 《ViewDF: Declarative incremental view maintenance for streaming data 》</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#multidirectional-replication-for-supporting-strong-consistency-low-latency-and-high-throughput"><span class="toc-number">10.</span> <span class="toc-text"> 《Multidirectional Replication for Supporting Strong Consistency, Low Latency, and High Throughput 》</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#pgce-a-distributed-storage-causal-consistency-model-based-on-partial-geo-replication-and-cloud-edge-collaboration-architecture"><span class="toc-number">11.</span> <span class="toc-text"> 《PGCE: A distributed storage causal consistency model based on partial geo-replication and cloud-edge collaboration architecture 》</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#replicated-data-types-that-unify-eventual-consistency-and-observable-atomic-consistency"><span class="toc-number">12.</span> <span class="toc-text"> 《Replicated data types that unify eventual consistency and observable atomic consistency 》</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#towards-the-synthesis-of-coherencereplication-protocols-from-consistency-models-via-real-time-orderings"><span class="toc-number">13.</span> <span class="toc-text"> 《Towards the Synthesis of Coherence&#x2F;Replication Protocols from Consistency Models via Real-Time Orderings 》</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#crdts%E4%B8%BB%E9%A2%98"><span class="toc-number">14.</span> <span class="toc-text"> CRDTs 主题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#deepsqueeze-deep-semantic-compression-for-tabular-data"><span class="toc-number">15.</span> <span class="toc-text"> 《DeepSqueeze: Deep Semantic Compression for Tabular Data 》</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#deepsqeeze%E7%9A%84%E5%8E%8B%E7%BC%A9%E8%BF%87%E7%A8%8B"><span class="toc-number">15.1.</span> <span class="toc-text"> DeepSqeeze 的压缩过程</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">15.1.1.</span> <span class="toc-text"> 预处理</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA"><span class="toc-number">15.1.2.</span> <span class="toc-text"> 模型构建</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%89%A9%E5%8C%96"><span class="toc-number">15.1.3.</span> <span class="toc-text"> 物化</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%A3%E5%8E%8B%E7%BC%A9"><span class="toc-number">15.2.</span> <span class="toc-text"> 解压缩</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#f1-query-declarative-querying-at-scale"><span class="toc-number">16.</span> <span class="toc-text"> 《F1 Query: Declarative Querying at Scale》</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8A%A8%E6%9C%BA"><span class="toc-number">16.1.</span> <span class="toc-text"> 动机</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E5%8A%BF"><span class="toc-number">16.2.</span> <span class="toc-text"> 优势</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#f1%E6%9F%A5%E8%AF%A2%E6%9E%B6%E6%9E%84%E7%9A%84%E6%A6%82%E8%BF%B0"><span class="toc-number">16.3.</span> <span class="toc-text"> F1 查询架构的概述</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%9E%B6%E6%9E%84"><span class="toc-number">16.3.1.</span> <span class="toc-text"> 架构</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%9F%A5%E8%AF%A2%E6%89%A7%E8%A1%8C"><span class="toc-number">16.3.2.</span> <span class="toc-text"> 查询执行</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90"><span class="toc-number">16.3.3.</span> <span class="toc-text"> 数据来源</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E4%B8%8B%E7%A7%BB"><span class="toc-number">16.3.4.</span> <span class="toc-text"> 数据下移</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%9F%A5%E8%AF%A2%E8%AF%AD%E8%A8%80"><span class="toc-number">16.3.5.</span> <span class="toc-text"> 查询语言</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%89%A7%E8%A1%8C%E5%86%85%E6%A0%B8%E5%92%8C%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%BC%8F"><span class="toc-number">16.4.</span> <span class="toc-text"> 执行内核和交互式执行模式</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8D%95%E7%BA%BF%E7%A8%8B%E6%89%A7%E8%A1%8C%E5%86%85%E6%A0%B8"><span class="toc-number">16.4.1.</span> <span class="toc-text"> 单线程执行内核</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E6%89%A7%E8%A1%8C"><span class="toc-number">16.4.2.</span> <span class="toc-text"> 分布式执行</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5"><span class="toc-number">16.4.3.</span> <span class="toc-text"> 分区策略</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%80%A7%E8%83%BD%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"><span class="toc-number">16.4.4.</span> <span class="toc-text"> 性能注意事项</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8Emapreduce%E7%9A%84%E6%89%B9%E5%A4%84%E7%90%86%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%BC%8F"><span class="toc-number">16.5.</span> <span class="toc-text"> 基于 MapReduce 的批处理执行模式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#f1%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%E5%99%A8"><span class="toc-number">16.6.</span> <span class="toc-text"> F1 查询优化器</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#f1%E4%B8%AD%E7%9A%84%E5%90%84%E7%A7%8D%E6%89%A9%E5%B1%95%E6%80%A7%E9%80%89%E9%A1%B9"><span class="toc-number">16.7.</span> <span class="toc-text"> F1 中的各种扩展性选项</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#f1%E7%9A%84%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="toc-number">16.8.</span> <span class="toc-text"> F1 的结构化数据处理</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/08/24/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%9B%E7%BA%A7%E8%80%83%E8%AF%95/" title="计算机四级考试"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img1.imgtp.com/2023/08/24/eZeuF7ne.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="计算机四级考试"/></a><div class="content"><a class="title" href="/2023/08/24/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%9B%E7%BA%A7%E8%80%83%E8%AF%95/" title="计算机四级考试">计算机四级考试</a><time datetime="2023-08-24T06:39:06.000Z" title="发表于 2023-08-24 14:39:06">2023-08-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/31/sql%E8%AF%AD%E5%8F%A5/" title="SQL语句"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img1.imgtp.com/2023/08/24/EqFxQjft.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="SQL语句"/></a><div class="content"><a class="title" href="/2023/03/31/sql%E8%AF%AD%E5%8F%A5/" title="SQL语句">SQL语句</a><time datetime="2023-03-31T09:40:02.000Z" title="发表于 2023-03-31 17:40:02">2023-03-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/30/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/" title="数理统计"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img1.imgtp.com/2023/08/24/TuvOW2R3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="数理统计"/></a><div class="content"><a class="title" href="/2023/03/30/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/" title="数理统计">数理统计</a><time datetime="2023-03-30T06:24:48.000Z" title="发表于 2023-03-30 14:24:48">2023-03-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%89%E7%BA%A7%E8%80%83%E8%AF%95/" title="计算机三级填空题"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img1.imgtp.com/2023/08/24/ntzFO2LW.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="计算机三级填空题"/></a><div class="content"><a class="title" href="/2023/03/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%89%E7%BA%A7%E8%80%83%E8%AF%95/" title="计算机三级填空题">计算机三级填空题</a><time datetime="2023-03-29T01:48:10.000Z" title="发表于 2023-03-29 09:48:10">2023-03-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/28/%E8%AE%BA%E6%96%87/" title="论文阅读概要"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img1.imgtp.com/2023/08/24/0Jp2Kj9v.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="论文阅读概要"/></a><div class="content"><a class="title" href="/2023/03/28/%E8%AE%BA%E6%96%87/" title="论文阅读概要">论文阅读概要</a><time datetime="2023-03-28T10:51:10.000Z" title="发表于 2023-03-28 18:51:10">2023-03-28</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By 蟹堡王海星</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            if (node.hasAttribute('display')) {
              btf.wrap(node, 'div', { class: 'mathjax-overflow' })
            } else {
              btf.wrap(node, 'span', { class: 'mathjax-overflow' })
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script></div><div class="aplayer no-destroy" data-id="8850572104" data-server="tencent" data-type="playlist"   data-order="list" data-fixed="true"   data-preload="auto" data-autoplay="false" data-mutex="true" ></div><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-show-text.min.js" data-mobile="false" data-text="功德  +1" data-fontsize="15px" data-random="false" async="async"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></body></html>